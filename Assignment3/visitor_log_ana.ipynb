{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "#-----------------------------------------------------\n",
    "# This is a White House Visitor Log analysis in PySpark.\n",
    "#------------------------------------------------------\n",
    "# Input Parameters:\n",
    "#    argv[1]: String, input path\n",
    "#-------------------------------------------------------\n",
    "# @author YSH\n",
    "#-------------------------------------------------------\n",
    "from __future__ import print_function \n",
    "import sys \n",
    "from pyspark.sql import SparkSession \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"Usage: visitor_log_ana.py  <input-file>\", file=sys.stderr)\n",
    "        exit(-1)\n",
    "\n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"Visitor_Log_Ana\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "    #  sys.argv[0] is the name of the script.\n",
    "    #  sys.argv[1] is the first parameter\n",
    "    input_path = sys.argv[1]  \n",
    "    print(\"input_path: {}\".format(input_path))\n",
    "\n",
    "    # read input and create an RDD<String>\n",
    "    records = spark.sparkContext.textFile(input_path)\n",
    "    print(\"Total number of records (including the header): \", records.count())\n",
    "    print(\"Records examples: \", records.take(3))\n",
    "\n",
    "    # remove the header/first line/column names from the loaded file\n",
    "    header = records.first()\n",
    "    input_data = records.filter(lambda x: x != header)\n",
    "    print(\"Total number of records (without the header): \", input_data.count())\n",
    "\n",
    "\n",
    "    # convert all words to lowercase \n",
    "    # a. if a visitor's last name (i.e., NAMELAST) is null/empty, then drop that record\n",
    "    # b. if visitee_namelast is null/empty, then drop that record\n",
    "    rdd_filter = input_data.map(lambda x: x.lower().split(',')).filter(lambda x: x[0] and x[19])\n",
    "    print(\"Total number of records after dropping the invalid records: \", rdd_filter.count())\n",
    "\n",
    "    # Q1: The 10 most frequent visitors (NAMELAST, NAMEFIRST, NAMEMID) to the White House. \n",
    "    # <visitor> <frequency>\n",
    "    rdd_mf_visitors = rdd_filter.map(lambda x: ((x[0],x[1],x[2]), 1)).reduceByKey(lambda a,b: a+b)   \n",
    "    print(\"Q1 The 10 most frequent visitors with frequency: \",  rdd_mf_visitors.takeOrdered(10, key=lambda x: -x[1]))\n",
    "\n",
    "    \n",
    "    ## Q2: The 10 most frequently visited people (visitee_namelast, visitee_namefirst) in the White House.\n",
    "    ## <visitee> <frequency>\n",
    "    rdd_mf_visitee = rdd_filter.map(lambda x: ((x[19],x[20]), 1)).reduceByKey(lambda a,b: a+b)\n",
    "    print(\"Q2 The 10 most frequently visited people with frequency: \", rdd_mf_visitee.takeOrdered(10, key=lambda x: -x[1]))\n",
    "\n",
    "    # Q3: The 10 most frequent visitor-visitee combinations.\n",
    "    # <visitor-visitee> <frequency>\n",
    "    rdd_mf_vv = rdd_filter.map(lambda x: ((x[0],x[1],x[2],x[19],x[20]), 1)).reduceByKey(lambda a,b: a+b)    \n",
    "    print(\"Q3 The 10 most frequent visitor-visitee combinations with frequency: \", rdd_mf_vv.takeOrdered(10, key=lambda x: -x[1]))\n",
    "    \n",
    "    # Q4: The number of records dropped.\n",
    "    print(\"Q4 The number of records dropped: \", input_data.count()- rdd_filter.count())\n",
    "    \n",
    "    # done!\n",
    "    spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
